---
title: "Desafio 1"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE)

```

## Pacotes

```{r, warning = FALSE, message= FALSE}
library("readr")
library("dplyr")
library("ggplot2")
library("caret")
library("randomForest")
library("ggfortify")
library("xgboost")
library("mlbench")

```

## Dados 
```{r, message=FALSE}
data<- read.csv("train.csv")

```
## Variaveis
```{r}

summary(data)
str(data)



```







## Modelos
```{r}

#Transformando as variaveis em fatores e removendo User_ID e Product_ID que não são interessantes
data<- data %>% select(-c(User_ID, Product_ID)) %>% mutate_at(vars(Gender, Occupation, Stay_In_Current_City_Years, Marital_Status, City_Category, Age, Product_Category_1, Product_Category_2, Product_Category_3), as.factor) 


#Classificando se o produto se encontra em mais de uma categoria 
data<- data %>% mutate(product = 3 - is.na(Product_Category_2)- is.na(Product_Category_3)) 

#Separando em treino e teste
indice_treino = createDataPartition(y= data$Purchase, p=0.7, list=FALSE)
treino = data[indice_treino, ]
teste = data[-indice_treino, ]

#1°Modelo - Regressão Linear 
modelo_lm<- lm(Purchase ~ Gender+Age+Occupation+City_Category+Stay_In_Current_City_Years+
                  Marital_Status+Product_Category_1+ as.integer(product),data = treino)

val_atual<- teste$Purchase
pred_lm <- predict(modelo_lm, teste)

#Checando acuracia 
mse_lm = mean((val_atual - pred_lm)^2)
mae_lm = caret::MAE(val_atual, pred_lm)
rmse_lm = caret::RMSE(val_atual, pred_lm)
cat("MSE: ", mse_lm, "MAE: ", mae_lm, " RMSE: ", rmse_lm)


#2° Modelo - XGBoost 

#Coletando o X e Y de cada set e  transformando em matrizes 
treino_x<- treino %>% select(-c('Purchase', 'Product_Category_2', 'Product_Category_3'))
treino_x = data.matrix(treino_x)
treino_y = treino$Purchase


teste_x<- teste %>% select(-c('Purchase', 'Product_Category_2', 'Product_Category_3'))
teste_x = data.matrix(teste_x)
teste_y = teste$Purchase

xgb_treino = xgb.DMatrix(data = treino_x, label = treino_y)
xgb_teste = xgb.DMatrix(data = teste_x, label = teste_y)

#Aplicando o modelo 
xgbc = xgboost(data = xgb_treino, max.depth = 2, nrounds = 50, booster = "gbtree")
print(xgbc)

#Predições 
pred_xgb = predict(xgbc, xgb_teste)

#Checando acuracia 
mse = mean((teste_y - pred_xgb)^2)
mae = caret::MAE(teste_y, pred_xgb)
rmse = caret::RMSE(teste_y, pred_xgb)

cat("MSE: ", mse, "MAE: ", mae, " RMSE: ", rmse)

postResample(pred_xgb, val_atual)


```
## Resultados
#### Comparando os erros entre os dois modelos, o modelo de regressão linear apresentou melhores resultados.Além de RMSE mais baixo, também se apresentou um modelo com a maioria de suas variaveis como estatisticamente significativas. A escolha do RMSE como metrica para a escolha do melhor modelo se deu pele seu beneficio de penalizar erros de maior magnitude. Além de um RMSE mais baixo, o modelo linear apresentou bons resultados quanto ao p-valor e o R ajustado.

```{r}
summary(modelo_lm)

```
#### As categorias mais importantes para a predição ficaram entre gênero, idade e ocupação do cliente.

```{r}
importance_lm <- varImp(modelo_lm, scale=FALSE)
head(importance_lm, 10)

```
#### Pelo grafico de normalidade é possivel ver que os erros tendem a se distribuirem normalmente.  
```{r}
autoplot(modelo_lm, 2)
```

#### O modelo apesar de simples, cumpre seu papel em mostrar as melhores features e fazer estimativas, mas poderia ser melhorado com o tempo atraves de tuning e mais dados. 

